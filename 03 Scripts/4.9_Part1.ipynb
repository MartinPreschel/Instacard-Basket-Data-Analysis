{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69965823-a3a1-4de0-b27d-a91835b48320",
   "metadata": {},
   "source": [
    "# Import Data (Task 1-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddc4bfb-4c6b-483c-ba6a-e0cfacfc6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab75ecc-1b80-4c33-8a8f-eff2765a81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set path\n",
    "\n",
    "path = r\"/Users/martin/anaconda_projects/11-02-2025 Instacart Basket Analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08232bdb-3a88-4cbc-89ab-f639d3a8a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import customers data set \n",
    "\n",
    "df_customers = pd.read_csv(os.path.join(path, '02 data' , 'Original Data' , 'customers.csv'))\n",
    "\n",
    "ords_prods_merge = pd.read_pickle(os.path.join(path, '02 data' , 'Prepared Data' , 'ords_prods_merge.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f1102-7ac7-4274-9fb2-c5576ad75e7b",
   "metadata": {},
   "source": [
    "# Daten-Wrangling (Task 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae5ca9-51ec-4174-aab2-4e09f47672ea",
   "metadata": {},
   "source": [
    "## 4.1. Get an overview \n",
    "\n",
    "- To get an impression of the columns and data types\n",
    "- To recognize possible problems such as missing values or mixed data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c360a5-0118-4d4a-be90-022a83750f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Surnam</th>\n",
       "      <th>Gender</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>n_dependants</th>\n",
       "      <th>fam_status</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26711</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>Esquivel</td>\n",
       "      <td>Female</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>48</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>165665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33890</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>Hart</td>\n",
       "      <td>Female</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>36</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>59285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65803</td>\n",
       "      <td>Kenneth</td>\n",
       "      <td>Farley</td>\n",
       "      <td>Male</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>35</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>married</td>\n",
       "      <td>99568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125935</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Hicks</td>\n",
       "      <td>Female</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>40</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>42049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130797</td>\n",
       "      <td>Ann</td>\n",
       "      <td>Gilmore</td>\n",
       "      <td>Female</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>26</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>40374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id First Name    Surnam  Gender       STATE  Age date_joined  \\\n",
       "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
       "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
       "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
       "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
       "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
       "\n",
       "   n_dependants fam_status  income  \n",
       "0             3    married  165665  \n",
       "1             0     single   59285  \n",
       "2             2    married   99568  \n",
       "3             0     single   42049  \n",
       "4             1    married   40374  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fd043-1a2a-417a-8523-06567c3387d0",
   "metadata": {},
   "source": [
    "##  4.2 Revise Column Names  \n",
    "\n",
    "To improve **consistency, readability, and clarity**, the following column names have been revised:  \n",
    "\n",
    "###  Changes Applied:\n",
    "- **\"First Name\"** → `first_name` *(converted to snake_case)*\n",
    "- **\"Surnam\"** → `last_name` *(corrected typo, changed to last name for clarity)*\n",
    "- **\"Gender\"** → `gender` *(converted to lowercase for consistency)*\n",
    "- **\"STATE\"** → `state` *(converted to lowercase for consistency)*\n",
    "- **\"Age\"** → `age` *(converted to lowercase for consistency)*\n",
    "- **\"date_joined\"** → *Possibly should be converted to a date format (`datetime`) for better usability.*\n",
    "- **\"n_dependants\"** → `num_dependants` *(renamed for clarity)*\n",
    "- **\"fam_status\"** → `family_status` *(renamed for better understanding)*\n",
    "- **\"income\"** →  *No changes needed (already clear and consistent).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d304110a-8289-414a-ad0f-0548a1953f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.rename(columns={\n",
    "    'First Name': 'first_name',\n",
    "    'Surnam': 'last_name',\n",
    "    'Gender': 'gender',\n",
    "    'STATE': 'state',\n",
    "    'Age': 'age',\n",
    "    'n_dependants': 'num_dependants',\n",
    "    'fam_status': 'family_status'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8083b7c-6560-47ee-932c-c60784390bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'first_name', 'last_name', 'gender', 'state', 'age',\n",
      "       'date_joined', 'num_dependants', 'family_status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check whether the columns have been renamed correctly\n",
    "\n",
    "print(df_customers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238706b-97f0-4341-9916-a256cddc90b0",
   "metadata": {},
   "source": [
    "## 4.3 check & correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed0479e-6547-453e-a5aa-5352c641aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   user_id         206209 non-null  int64 \n",
      " 1   first_name      194950 non-null  object\n",
      " 2   last_name       206209 non-null  object\n",
      " 3   gender          206209 non-null  object\n",
      " 4   state           206209 non-null  object\n",
      " 5   age             206209 non-null  int64 \n",
      " 6   date_joined     206209 non-null  object\n",
      " 7   num_dependants  206209 non-null  int64 \n",
      " 8   family_status   206209 non-null  object\n",
      " 9   income          206209 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2eef21-e898-40da-b6b2-f9e7e160272b",
   "metadata": {},
   "source": [
    "##  What Should I Adjust?  \n",
    "\n",
    "### 1️ **Convert \"date_joined\" to Datetime Format**  \n",
    "- Currently stored as an **object (string)**.  \n",
    "- Should be converted to **datetime format** for better usability in time-based analyses.  \n",
    "\n",
    "### 2️ **Handle Missing Values in \"first_name\"**  \n",
    "- \"first_name\" has **fewer values** than other columns:  \n",
    "  - **194,950** entries vs. **206,209** total rows.  \n",
    "  - This indicates **missing values**.  \n",
    "- If I need to use this column, I should decide how to handle the missing values:  \n",
    "  - **Option 1:** Fill with an empty string (`\"\"`).  \n",
    "  - **Option 2:** Replace with `NaN` for easier filtering.  \n",
    "  - **Option 3:** Remove the column if it’s not essential for analysis.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0cc033-d6f7-419b-9648-d71feafb018d",
   "metadata": {},
   "source": [
    "## 4.4 Changing 'date_joined' to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "237b7d66-410a-4569-ba4d-3b878fc572c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers['date_joined'] = pd.to_datetime(df_customers['date_joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffaf3387-4e1a-43d7-accf-9603301a6e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   user_id         206209 non-null  int64         \n",
      " 1   first_name      194950 non-null  object        \n",
      " 2   last_name       206209 non-null  object        \n",
      " 3   gender          206209 non-null  object        \n",
      " 4   state           206209 non-null  object        \n",
      " 5   age             206209 non-null  int64         \n",
      " 6   date_joined     206209 non-null  datetime64[ns]\n",
      " 7   num_dependants  206209 non-null  int64         \n",
      " 8   family_status   206209 non-null  object        \n",
      " 9   income          206209 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(5)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking if the format for 'date_joined' is now correct\n",
    "\n",
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86efdcf7-1df3-4b09-b0c8-dd3edbfddc0b",
   "metadata": {},
   "source": [
    "##  4.5 Handling the \"first_name\" Column  \n",
    "\n",
    "###  Issue Identified:\n",
    "- The **`first_name`** column contains **missing values**, whereas **`last_name`** remains complete.  \n",
    "- Since `first_name` is **not essential for the analysis** and does not provide additional value beyond `last_name`, it can be removed.  \n",
    "\n",
    "###  Decision & Rationale:\n",
    "- **Removing unnecessary columns** helps to:  \n",
    "  - **Streamline the dataset**, making it more efficient.  \n",
    "  - **Reduce complexity**, ensuring cleaner and more manageable data.  \n",
    "  - **Improve performance** in further analysis.  \n",
    "\n",
    "By eliminating `first_name`, I ensure that only **relevant and complete** data is retained for processing.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca41840c-5e1a-4377-8351-f1c14bbfcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.drop(columns=['first_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6b0eaaa-1e70-4837-a33b-9b2289579bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'last_name', 'gender', 'state', 'age', 'date_joined',\n",
      "       'num_dependants', 'family_status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check whether the column first_name have been removed correctly\n",
    "\n",
    "print(df_customers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf562e-82c2-4364-9760-08219f417a34",
   "metadata": {},
   "source": [
    "###  Adjusting Column Names for Simplicity & Consistency  \n",
    "\n",
    "As part of the process of **removing the `first_name` column**, I will **rename `last_name` to `customer_name`** to maintain:  \n",
    "\n",
    " **Simplicity** – A single column for customer identification.  \n",
    " **Consistency** – Aligns with other column naming conventions.  \n",
    " **Clarity** – Avoids confusion by using a broader, more descriptive term.  \n",
    "\n",
    "This adjustment ensures a **cleaner dataset** while retaining all necessary information for further analysis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e387c66b-82b5-4330-9437-497bc136a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.rename(columns = {'last_name' : 'customer_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daae9069-ef17-410b-8bb6-044894bb1273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'customer_name', 'gender', 'state', 'age', 'date_joined',\n",
      "       'num_dependants', 'family_status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check whether the columns have been renamed correctly\n",
    "\n",
    "print(df_customers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06ad9d-a330-4b4b-baa7-828fce9a12f1",
   "metadata": {},
   "source": [
    "# Task 5) Data quality and consistency checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2beea-7bc0-47a7-ba2b-fcbb66da8210",
   "metadata": {},
   "source": [
    "##  5.1 Check & Handle Missing Values  \n",
    "\n",
    "###  Are There Missing Values in Other Columns?  \n",
    "- We previously identified **missing values** in the `first_name` column.  \n",
    "- Now, we need to check whether **other columns** also contain missing data.  \n",
    "\n",
    "###  Next Steps:  \n",
    " Perform a **missing value check** across all columns.  \n",
    " Decide on the appropriate **handling strategy** (e.g., filling, removing, or keeping as NaN).  \n",
    "\n",
    "Identifying and addressing missing values is essential to ensure **data integrity and reliability** in further analysis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b2a404f-e5fe-4ef3-9f62-16f30ebe6412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           0\n",
       "customer_name     0\n",
       "gender            0\n",
       "state             0\n",
       "age               0\n",
       "date_joined       0\n",
       "num_dependants    0\n",
       "family_status     0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with:\n",
    "\n",
    "df_customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b23b0-51ea-44e9-948e-829e82948f7c",
   "metadata": {},
   "source": [
    "### Result: There are no further values missing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1b273-bbbf-4202-b8fe-1ea2fca9d758",
   "metadata": {},
   "source": [
    "###  Result: No Further Missing Values Found!  \n",
    "\n",
    "After performing a comprehensive check, we confirmed that **no additional missing values** exist in the dataset.  \n",
    "\n",
    "###  Key Takeaways:  \n",
    "- The previously identified issue with `first_name` was addressed.  \n",
    "- All remaining columns contain **complete data**, ensuring data integrity.  \n",
    "- No further action is needed regarding missing values.  \n",
    "\n",
    "With this confirmation, we can proceed confidently with the next steps in the analysis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "162d0908-655d-42de-b36a-ae5409bf3182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with:\n",
    "\n",
    "df_customers.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34688cd8-f09c-471e-8f86-e5dea2d0d49b",
   "metadata": {},
   "source": [
    "###  Result: No Duplicates Found in the Dataframe!  \n",
    "\n",
    "After performing a duplicate check, we confirmed that **there are no duplicate entries** in the dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2603304-eaba-48a7-9069-b0756f0d99a9",
   "metadata": {},
   "source": [
    "# Task 6) Combining Customer Data with Prepared Instacart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b661787-85ef-4052-81f6-3f8ff333a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>...</th>\n",
       "      <th>prices</th>\n",
       "      <th>Busiest day</th>\n",
       "      <th>Busiest days</th>\n",
       "      <th>busiest_period_of_day</th>\n",
       "      <th>max_order</th>\n",
       "      <th>loyalty_flag</th>\n",
       "      <th>avg_spending</th>\n",
       "      <th>spending_flag</th>\n",
       "      <th>median_days_since_order</th>\n",
       "      <th>order_frequency_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Average orders</td>\n",
       "      <td>10</td>\n",
       "      <td>New Customer</td>\n",
       "      <td>6.367797</td>\n",
       "      <td>Low spender</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14084</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Average orders</td>\n",
       "      <td>10</td>\n",
       "      <td>New Customer</td>\n",
       "      <td>6.367797</td>\n",
       "      <td>Low spender</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12427</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Average orders</td>\n",
       "      <td>10</td>\n",
       "      <td>New Customer</td>\n",
       "      <td>6.367797</td>\n",
       "      <td>Low spender</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26088</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Average orders</td>\n",
       "      <td>10</td>\n",
       "      <td>New Customer</td>\n",
       "      <td>6.367797</td>\n",
       "      <td>Low spender</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26405</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Regularly busy</td>\n",
       "      <td>Average orders</td>\n",
       "      <td>10</td>\n",
       "      <td>New Customer</td>\n",
       "      <td>6.367797</td>\n",
       "      <td>Low spender</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  order_id  user_id eval_set  order_number  orders_day_of_week  \\\n",
       "0           0   2539329        1    prior             1                   2   \n",
       "1           0   2539329        1    prior             1                   2   \n",
       "2           0   2539329        1    prior             1                   2   \n",
       "3           0   2539329        1    prior             1                   2   \n",
       "4           0   2539329        1    prior             1                   2   \n",
       "\n",
       "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
       "0                  8                     NaN         196                  1   \n",
       "1                  8                     NaN       14084                  2   \n",
       "2                  8                     NaN       12427                  3   \n",
       "3                  8                     NaN       26088                  4   \n",
       "4                  8                     NaN       26405                  5   \n",
       "\n",
       "   ...  prices     Busiest day    Busiest days  busiest_period_of_day  \\\n",
       "0  ...     9.0  Regularly busy  Regularly busy         Average orders   \n",
       "1  ...    12.5  Regularly busy  Regularly busy         Average orders   \n",
       "2  ...     4.4  Regularly busy  Regularly busy         Average orders   \n",
       "3  ...     4.7  Regularly busy  Regularly busy         Average orders   \n",
       "4  ...     1.0  Regularly busy  Regularly busy         Average orders   \n",
       "\n",
       "   max_order  loyalty_flag avg_spending spending_flag median_days_since_order  \\\n",
       "0         10  New Customer     6.367797   Low spender                    20.5   \n",
       "1         10  New Customer     6.367797   Low spender                    20.5   \n",
       "2         10  New Customer     6.367797   Low spender                    20.5   \n",
       "3         10  New Customer     6.367797   Low spender                    20.5   \n",
       "4         10  New Customer     6.367797   Low spender                    20.5   \n",
       "\n",
       "    order_frequency_flag  \n",
       "0  Non-frequent customer  \n",
       "1  Non-frequent customer  \n",
       "2  Non-frequent customer  \n",
       "3  Non-frequent customer  \n",
       "4  Non-frequent customer  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before starting: Getting an overview of ords_prods_merge\n",
    "\n",
    "ords_prods_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74ace0-8cf2-4116-9e4c-2f25e52f802c",
   "metadata": {},
   "source": [
    "###  Result: Matching `user_id` Column Found!  \n",
    "\n",
    "Since **`ords_prods_merge`** contains a `user_id` column, just like **`df_customers`**, we can proceed with the next step.  \n",
    "\n",
    "###  Next Steps:  \n",
    " **Step 1: Check Key Columns**  \n",
    "- Ensure that `user_id` is in the correct **data type** for merging.  \n",
    "- Verify that there are **no inconsistencies** in `user_id` between the datasets.  \n",
    "\n",
    "With this confirmation, we are ready to proceed with merging the datasets for further analysis.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885c669-da29-48bf-bd67-88a9b7da66e6",
   "metadata": {},
   "source": [
    "##  6.1 Check Key Columns (Data Type)  \n",
    "\n",
    "###  Why Check Data Types?  \n",
    "Before merging the datasets, we need to ensure that **`user_id`** has the **same data type** in both `ords_prods_merge` and `df_customers`.  \n",
    "\n",
    "###  Next Steps:  \n",
    " Verify the **data type** of `user_id` in both DataFrames.  \n",
    " If necessary, **convert data types** to match and avoid merge conflicts.  \n",
    " Ensure consistency to facilitate a smooth and accurate merge.  \n",
    "\n",
    "Checking key columns is essential to prevent **errors and inconsistencies** in the data integration process.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6726d1f-9906-4f77-9e79-99251e235657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_customers['user_id'].dtype)\n",
    "print(ords_prods_merge['user_id'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d167e-6096-4db8-b93c-19231ba2c4fb",
   "metadata": {},
   "source": [
    "Result: Both user_id columns have the data type **int64**, so no conversion is required. I can continue directly with the merging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2ce4b1c-578c-4170-ab5e-6f438ba2bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206209, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape check 'df_customers'\n",
    "\n",
    "df_customers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60cf0454-99c5-4f1c-b4d0-c7917fa22bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32434212, 25)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape check 'ords_prods_merge'\n",
    "\n",
    "ords_prods_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb0dda-f6c9-4aac-bda6-44dc34b65181",
   "metadata": {},
   "source": [
    "##  6.2 Perform Merge  \n",
    "\n",
    "Since the `user_id` columns match in both DataFrames, we can now **combine `df_customers` with `ords_prods_merge`** to enrich our dataset with customer information.  \n",
    "\n",
    "###  Next Steps:  \n",
    " Perform a **merge operation** using `user_id` as the key.  \n",
    " Ensure that the **merge type** (`left`, `inner`, etc.) is chosen correctly to preserve the required data.  \n",
    " Verify that the resulting dataset contains the expected number of rows and columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e05e5d39-4187-46dd-ac79-3df4a838c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = ords_prods_merge.merge(df_customers, on='user_id', how='left')\n",
    "\n",
    "# Why how='left'?\n",
    "# - This way, all orders are retained, even if not every user_id appears in the customer data.\n",
    "# - If you only want to keep customer data that is also in ords_prods_merge, you could use inner - but left makes more sense here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e12c2-debf-4fc1-9367-372881968cd9",
   "metadata": {},
   "source": [
    "##  6.3 Checking After the Merge  \n",
    "\n",
    "###  Verification Step: Were the New Columns Added?  \n",
    "After merging `df_customers` with `ords_prods_merge`, we need to confirm that the new customer-related columns have been successfully integrated.  \n",
    "\n",
    "###  Key Checks:  \n",
    " **Are the new columns from `df_customers` present** in the merged DataFrame?  \n",
    " **Is the total number of rows unchanged**, ensuring that no data was lost during the merge?  \n",
    " **Do the new columns contain expected values**, without excessive missing (`NaN`) entries?  \n",
    "\n",
    "Verifying the merge is essential to ensure **data integrity** before proceeding with further analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2de0a3e1-d116-4de7-a7d2-7f95a4a7e72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>...</th>\n",
       "      <th>median_days_since_order</th>\n",
       "      <th>order_frequency_flag</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>num_dependants</th>\n",
       "      <th>family_status</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14084</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12427</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26088</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26405</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Non-frequent customer</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Female</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>40423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  order_id  user_id eval_set  order_number  orders_day_of_week  \\\n",
       "0           0   2539329        1    prior             1                   2   \n",
       "1           0   2539329        1    prior             1                   2   \n",
       "2           0   2539329        1    prior             1                   2   \n",
       "3           0   2539329        1    prior             1                   2   \n",
       "4           0   2539329        1    prior             1                   2   \n",
       "\n",
       "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
       "0                  8                     NaN         196                  1   \n",
       "1                  8                     NaN       14084                  2   \n",
       "2                  8                     NaN       12427                  3   \n",
       "3                  8                     NaN       26088                  4   \n",
       "4                  8                     NaN       26405                  5   \n",
       "\n",
       "   ...  median_days_since_order   order_frequency_flag customer_name  gender  \\\n",
       "0  ...                     20.5  Non-frequent customer        Nguyen  Female   \n",
       "1  ...                     20.5  Non-frequent customer        Nguyen  Female   \n",
       "2  ...                     20.5  Non-frequent customer        Nguyen  Female   \n",
       "3  ...                     20.5  Non-frequent customer        Nguyen  Female   \n",
       "4  ...                     20.5  Non-frequent customer        Nguyen  Female   \n",
       "\n",
       "     state  age date_joined num_dependants family_status  income  \n",
       "0  Alabama   31  2019-02-17              3       married   40423  \n",
       "1  Alabama   31  2019-02-17              3       married   40423  \n",
       "2  Alabama   31  2019-02-17              3       married   40423  \n",
       "3  Alabama   31  2019-02-17              3       married   40423  \n",
       "4  Alabama   31  2019-02-17              3       married   40423  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad229629-400d-48d7-a69c-0d94a7eeb073",
   "metadata": {},
   "source": [
    "Result: The columns are added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13b0fb-c260-46bd-b658-62b3eba50fe2",
   "metadata": {},
   "source": [
    "###  Row Count Validation: Has the Number of Lines Remained the Same?  \n",
    "\n",
    "After merging `df_customers` with `ords_prods_merge`, it is crucial to confirm that the **number of rows has not decreased** to ensure that no data was lost in the process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f3c45a7-6cff-4e6a-84f0-58f28e6f78be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32434212, 25)\n",
      "(32434212, 33)\n"
     ]
    }
   ],
   "source": [
    "print(ords_prods_merge.shape)\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f79eeb-d31c-466c-9318-2b9754884ac9",
   "metadata": {},
   "source": [
    "### Result: Everything is Correct!  \n",
    "\n",
    "The merge was successful, and all key validation checks have been passed:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a095aa-2dbe-4ff3-8ab5-6af2c6ead8a5",
   "metadata": {},
   "source": [
    "### Are There Any Missing Values in the New Columns?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c9d9160-72a1-4529-b6cd-02d35b59228a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                       0\n",
       "order_id                         0\n",
       "user_id                          0\n",
       "eval_set                         0\n",
       "order_number                     0\n",
       "orders_day_of_week               0\n",
       "order_hour_of_day                0\n",
       "days_since_prior_order     2078084\n",
       "product_id                       0\n",
       "add_to_cart_order                0\n",
       "reordered                        0\n",
       "_merge                           0\n",
       "product_name                 28171\n",
       "aisle_id                         0\n",
       "department_id                    0\n",
       "prices                           0\n",
       "Busiest day                      0\n",
       "Busiest days                     0\n",
       "busiest_period_of_day            0\n",
       "max_order                        0\n",
       "loyalty_flag                     0\n",
       "avg_spending                     0\n",
       "spending_flag                    0\n",
       "median_days_since_order          0\n",
       "order_frequency_flag             0\n",
       "customer_name                    0\n",
       "gender                           0\n",
       "state                            0\n",
       "age                              0\n",
       "date_joined                      0\n",
       "num_dependants                   0\n",
       "family_status                    0\n",
       "income                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5a35a-140e-496d-a03a-9b6b9983e9e9",
   "metadata": {},
   "source": [
    "###  Result & Next Steps  \n",
    "\n",
    "The merge was successful, and we have verified the presence of missing values in the dataset.  \n",
    "\n",
    "###  Key Findings:  \n",
    "1️ **No missing values** were found in the newly added columns from `df_customers` – the merge worked correctly!  \n",
    "2️ **Most missing values** are in the `days_po` and `product_name` columns, which are related to orders and products.  \n",
    "3️ **These NaN values are expected** and may not require immediate correction.  \n",
    "\n",
    "###  Next Steps:  \n",
    " Decide whether to **replace NaN values** (e.g., filling `days_po` with `0` for first-time orders or replacing `product_name` with `\"Unknown Product\"`).  \n",
    " Alternatively, **leave NaN values as they are** if they do not affect further analysis.  \n",
    "\n",
    "By confirming these results, we ensure **data integrity** and can proceed confidently with the next analytical steps.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07133dbe-ada5-48ba-aa74-4a94d26ac13c",
   "metadata": {},
   "source": [
    "##  Handling Missing Values  \n",
    "\n",
    "###  Decision: Keep `NaN` Values for Data Integrity  \n",
    "\n",
    "During the data quality check, I identified **missing values** in the `days_po` and `product_name` columns. Instead of making assumptions and filling these values with arbitrary replacements, I decided to **retain them as `NaN`** for the following reasons:  \n",
    "\n",
    "###  Why Keep `NaN` Values?  \n",
    "- **Maintains Data Integrity** – Prevents introducing incorrect or misleading values.  \n",
    "- **Ensures Analytical Flexibility** – `NaN` values can be easily identified and handled when needed.  \n",
    "- **Avoids Potential Biases** – Filling missing values without context could distort analysis results.  \n",
    "\n",
    "###  Future Considerations:  \n",
    "- If necessary, missing values can be addressed later based on **specific analytical needs**.  \n",
    "- Further exploration may determine if `days_po` missing values indicate **first-time orders** or another pattern.  \n",
    "- `product_name` missing values could be replaced with `\"Unknown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4abd29-3a25-4c43-84dd-803b3ff9d89e",
   "metadata": {},
   "source": [
    "# Task 8) Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94b7b9b7-cbca-4ace-ac4e-a8f3dfb2ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to pkl\n",
    "df_merged.to_pickle(os.path.join(path, '02 Data','Prepared Data', 'orders_products_customers_combined.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce30e9-8cd1-49a4-83d9-932cb05e5322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
